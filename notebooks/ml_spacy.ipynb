{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a869b620-2334-456e-acc7-07f8e7f101bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import functions as func\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# load data sets\n",
    "db_locations = func.import_yaml()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2253779-29c3-4114-81d9-760f26d18b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load formated DS\n",
    "df = pd.read_csv(db_locations['data_clean']['spacy_train'])\n",
    "df_test = pd.read_csv(db_locations['data_clean']['spacy_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5b98c39-b72c-4259-8e24-cecf23e18c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>series escapade demonstrate adage good goose g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>series escapade demonstrate adage good goose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>series</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment                                       cleaned_text  \n",
       "0          1  series escapade demonstrate adage good goose g...  \n",
       "1          2       series escapade demonstrate adage good goose  \n",
       "2          2                                             series  \n",
       "3          2                                                NaN  \n",
       "4          2                                             series  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60edaf3d-52d8-45f5-a054-f1bebb58becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId  SentenceId  Phrase  Sentiment  cleaned_text\n",
       "False     False       False   False      False           153384\n",
       "                                         True              2676\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c883ec71-fad5-4d6d-a710-d4c4ebcd18e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing routine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "                             cleaned_text  \n",
       "0  intermittently pleasing routine effort  \n",
       "1  intermittently pleasing routine effort  \n",
       "2                                     NaN  \n",
       "3  intermittently pleasing routine effort  \n",
       "4         intermittently pleasing routine  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e604ce7-8aea-47a1-b9ad-d649049c3f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>what</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155587</th>\n",
       "      <td>155588</td>\n",
       "      <td>8515</td>\n",
       "      <td>a few others</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155588</th>\n",
       "      <td>155589</td>\n",
       "      <td>8515</td>\n",
       "      <td>few others</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155591</th>\n",
       "      <td>155592</td>\n",
       "      <td>8515</td>\n",
       "      <td>do n't make often enough</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155592</th>\n",
       "      <td>155593</td>\n",
       "      <td>8515</td>\n",
       "      <td>make often enough</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155763</th>\n",
       "      <td>155764</td>\n",
       "      <td>8525</td>\n",
       "      <td>to him</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                    Phrase  Sentiment cleaned_text\n",
       "3              4           1                         A          2          NaN\n",
       "6              7           1                        of          2          NaN\n",
       "13            14           1                       the          2          NaN\n",
       "16            17           1                      that          2          NaN\n",
       "18            19           1                      what          2          NaN\n",
       "...          ...         ...                       ...        ...          ...\n",
       "155587    155588        8515              a few others          2          NaN\n",
       "155588    155589        8515                few others          2          NaN\n",
       "155591    155592        8515  do n't make often enough          2          NaN\n",
       "155592    155593        8515         make often enough          2          NaN\n",
       "155763    155764        8525                    to him          2          NaN\n",
       "\n",
       "[2676 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cleaned_text.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aaef6d6-1855-4a7d-bb9f-3c35b75b507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.cleaned_text.isnull()& df.Sentiment == 1].sort_values('Phrase').duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f01046e-0c0a-4ae3-87e2-2655751cb34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhraseId  SentenceId  Phrase  cleaned_text\n",
       "False     False       False   False           64829\n",
       "                              True             1462\n",
       "                      True    True                1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "726b689a-7928-4134-893e-4ce345c54130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156072</td>\n",
       "      <td>8545</td>\n",
       "      <td>mostly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>156075</td>\n",
       "      <td>8545</td>\n",
       "      <td>.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>156080</td>\n",
       "      <td>8546</td>\n",
       "      <td>is really</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66126</th>\n",
       "      <td>222187</td>\n",
       "      <td>11844</td>\n",
       "      <td>not quite enough</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66127</th>\n",
       "      <td>222188</td>\n",
       "      <td>11844</td>\n",
       "      <td>quite enough</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66216</th>\n",
       "      <td>222277</td>\n",
       "      <td>11850</td>\n",
       "      <td>-- but</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66248</th>\n",
       "      <td>222309</td>\n",
       "      <td>11852</td>\n",
       "      <td>even if you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66249</th>\n",
       "      <td>222310</td>\n",
       "      <td>11852</td>\n",
       "      <td>if you</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1463 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId            Phrase cleaned_text\n",
       "2        156063        8545                An          NaN\n",
       "9        156070        8545               but          NaN\n",
       "11       156072        8545            mostly          NaN\n",
       "14       156075        8545                 .          NaN\n",
       "19       156080        8546         is really          NaN\n",
       "...         ...         ...               ...          ...\n",
       "66126    222187       11844  not quite enough          NaN\n",
       "66127    222188       11844      quite enough          NaN\n",
       "66216    222277       11850            -- but          NaN\n",
       "66248    222309       11852       even if you          NaN\n",
       "66249    222310       11852            if you          NaN\n",
       "\n",
       "[1463 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.cleaned_text.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d21c02a-2885-4302-8ced-034b7dfed290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping nan columns for the first test\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df_test.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9420b27-99db-47cb-a703-e67d9d931a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing what we learned in class\n",
    "\n",
    "# Crop the sample size because the fowloing tests needed to much memory for current tests\n",
    "\n",
    "frac_df = df.sample(frac = 0.2)\n",
    "\n",
    "# Data preparation with TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000) \n",
    "\n",
    "X_train = tfidf.fit_transform(frac_df['cleaned_text']).toarray()\n",
    "X_test = tfidf.transform(df_test['cleaned_text']).toarray()\n",
    "\n",
    "# Target variable (Sentiment)\n",
    "y_train = frac_df['Sentiment']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff38ed59-4f68-48df-9441-2c87e1380c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Balance the data frame with SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb88ea1-04f2-46c3-b58a-52e5a779d348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tiago/Documents/GitHub/Projects/final_project/proj_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d4a54c8-4879-4d8a-a0bc-83bc4f704770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.11      0.18       274\n",
      "           1       0.46      0.24      0.32      1081\n",
      "           2       0.60      0.88      0.72      3101\n",
      "           3       0.49      0.34      0.40      1310\n",
      "           4       0.47      0.11      0.18       370\n",
      "\n",
      "    accuracy                           0.57      6136\n",
      "   macro avg       0.52      0.34      0.36      6136\n",
      "weighted avg       0.55      0.57      0.52      6136\n",
      "\n",
      "Validation Accuracy:  0.57\n",
      "MAE  0.49\n",
      "RMSE,  0.80\n",
      "R2 score,  0.66\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "print(classification_report(y_val_split, y_pred))\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33da9e1d-1f48-472a-92e6-d65037fb714f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 3, 2, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dff5f869-1d7d-4f4a-84ea-102a58275d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic KNN classifier model\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a KNN classifier model\n",
    "model = KNeighborsClassifier(n_neighbors=3) \n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10bf5493-51fc-458a-ac53-c93ed9a7f215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.26      0.27       274\n",
      "           1       0.33      0.25      0.29      1081\n",
      "           2       0.58      0.80      0.67      3101\n",
      "           3       0.47      0.23      0.31      1310\n",
      "           4       0.48      0.15      0.23       370\n",
      "\n",
      "    accuracy                           0.52      6136\n",
      "   macro avg       0.43      0.34      0.35      6136\n",
      "weighted avg       0.49      0.52      0.48      6136\n",
      "\n",
      "Validation Accuracy:  0.52\n",
      "MAE  0.59\n",
      "RMSE,  0.90\n",
      "R2 score,  0.71\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "print(classification_report(y_val_split, y_pred))\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7007a4-2e1c-4c92-8cca-4f4da51a5265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ec20f7c-23bf-418a-85e0-7e0c2e7d6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a AdaBoost model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = GradientBoostingRegressor(max_depth=5,\n",
    "                                   n_estimators=10)\n",
    "\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97571f95-7d5b-4bac-a2fc-64a976b24f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.27985071, 2.05365947, 2.05365947, ..., 2.28138816, 2.05365947,\n",
       "       2.05365947])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "681a929a-541d-477d-8f97-6cd970d6e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.61\n",
      "RMSE,  0.88\n",
      "R2 score,  0.05\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f1c50d-65e7-417c-9637-f33817b82ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62f55ee2-f126-4758-bae9-aadb35d38679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Decision Tree model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model =   DecisionTreeRegressor(max_depth=2)\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "#Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd8bae18-a4b1-4cc6-ae39-084943b684d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.65632458, 2.0601141 , 2.0601141 , ..., 2.0601141 , 2.0601141 ,\n",
       "       2.0601141 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b5b4b4c-76e4-4da4-a68d-165f0d8345e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.62\n",
      "RMSE,  0.89\n",
      "R2 score,  0.03\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31caf96c-8499-4108-9863-e84481071356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a  Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4fb5b6ba-fa3e-4080-8d6f-0b59e7a6a311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 3, 2, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e0c1cd3-1168-417b-9bac-64ff10bfead6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.24      0.35       274\n",
      "           1       0.61      0.38      0.47      1081\n",
      "           2       0.66      0.91      0.77      3101\n",
      "           3       0.61      0.48      0.54      1310\n",
      "           4       0.80      0.23      0.36       370\n",
      "\n",
      "    accuracy                           0.65      6136\n",
      "   macro avg       0.67      0.45      0.50      6136\n",
      "weighted avg       0.65      0.65      0.62      6136\n",
      "\n",
      "Validation Accuracy:  0.65\n",
      "MAE  0.40\n",
      "RMSE,  0.72\n",
      "R2 score,  0.66\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "print(classification_report(y_val_split, y_pred))\n",
    "print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52d04fb-fa80-41d5-a70c-263fdc9b4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging and Pasting model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = XGBClassifier()\n",
    "\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec221019-d939-495e-9103-3108267c3f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97106250-2aba-4073-9134-70ef6fb8fa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.15      0.23       274\n",
      "           1       0.51      0.12      0.19      1081\n",
      "           2       0.57      0.95      0.71      3101\n",
      "           3       0.47      0.18      0.26      1310\n",
      "           4       0.47      0.13      0.21       370\n",
      "\n",
      "    accuracy                           0.55      6136\n",
      "   macro avg       0.50      0.31      0.32      6136\n",
      "weighted avg       0.53      0.55      0.47      6136\n",
      "\n",
      "Validation Accuracy:  0.55\n",
      "MAE  0.53\n",
      "RMSE,  0.84\n",
      "R2 score,  0.63\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47ded4b8-fa10-459b-bddc-a94df3a85db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging and Pasting model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = BaggingRegressor(DecisionTreeRegressor(max_depth=5),\n",
    "                               n_estimators=10, \n",
    "                               max_samples = 10)\n",
    "\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c04747eb-1c7f-4cdb-9ad6-9520bee201ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.67\n",
      "RMSE,  0.90\n",
      "R2 score, -0.01\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebc00728-4b7f-4751-b728-9a8981c13a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.16, 2.16, 2.16, ..., 2.16, 2.16, 2.16])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "561a23fd-1f55-4d00-8201-cc35167ea8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Patches model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = RandomForestRegressor(n_estimators=10,\n",
    "                             max_depth=5)\n",
    "\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e1892fe-eeeb-4410-ae1f-cd19e7ba5070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.55396286, 2.04993103, 2.04993103, ..., 2.16519518, 2.04993103,\n",
       "       2.04993103])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "411f4299-494a-4c6b-a3e7-7128bf43122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE  0.61\n",
      "RMSE,  0.88\n",
      "R2 score,  0.06\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b14fdf4-cf6d-4aa5-8b8e-d91006c484a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=2, max_leaf_nodes=5...............................\n",
      "[CV 1/5; 1/9] END max_depth=2, max_leaf_nodes=5;, score=0.018 total time=   1.8s\n",
      "[CV 2/5; 1/9] START max_depth=2, max_leaf_nodes=5...............................\n",
      "[CV 2/5; 1/9] END max_depth=2, max_leaf_nodes=5;, score=0.028 total time=   1.8s\n",
      "[CV 3/5; 1/9] START max_depth=2, max_leaf_nodes=5...............................\n",
      "[CV 3/5; 1/9] END max_depth=2, max_leaf_nodes=5;, score=0.024 total time=   1.8s\n",
      "[CV 4/5; 1/9] START max_depth=2, max_leaf_nodes=5...............................\n",
      "[CV 4/5; 1/9] END max_depth=2, max_leaf_nodes=5;, score=0.016 total time=   1.8s\n",
      "[CV 5/5; 1/9] START max_depth=2, max_leaf_nodes=5...............................\n",
      "[CV 5/5; 1/9] END max_depth=2, max_leaf_nodes=5;, score=0.023 total time=   1.8s\n",
      "[CV 1/5; 2/9] START max_depth=2, max_leaf_nodes=25..............................\n",
      "[CV 1/5; 2/9] END max_depth=2, max_leaf_nodes=25;, score=0.018 total time=   1.8s\n",
      "[CV 2/5; 2/9] START max_depth=2, max_leaf_nodes=25..............................\n",
      "[CV 2/5; 2/9] END max_depth=2, max_leaf_nodes=25;, score=0.028 total time=   1.8s\n",
      "[CV 3/5; 2/9] START max_depth=2, max_leaf_nodes=25..............................\n",
      "[CV 3/5; 2/9] END max_depth=2, max_leaf_nodes=25;, score=0.024 total time=   1.8s\n",
      "[CV 4/5; 2/9] START max_depth=2, max_leaf_nodes=25..............................\n",
      "[CV 4/5; 2/9] END max_depth=2, max_leaf_nodes=25;, score=0.016 total time=   1.8s\n",
      "[CV 5/5; 2/9] START max_depth=2, max_leaf_nodes=25..............................\n",
      "[CV 5/5; 2/9] END max_depth=2, max_leaf_nodes=25;, score=0.023 total time=   1.9s\n",
      "[CV 1/5; 3/9] START max_depth=2, max_leaf_nodes=50..............................\n",
      "[CV 1/5; 3/9] END max_depth=2, max_leaf_nodes=50;, score=0.018 total time=   1.8s\n",
      "[CV 2/5; 3/9] START max_depth=2, max_leaf_nodes=50..............................\n",
      "[CV 2/5; 3/9] END max_depth=2, max_leaf_nodes=50;, score=0.028 total time=   1.8s\n",
      "[CV 3/5; 3/9] START max_depth=2, max_leaf_nodes=50..............................\n",
      "[CV 3/5; 3/9] END max_depth=2, max_leaf_nodes=50;, score=0.024 total time=   1.8s\n",
      "[CV 4/5; 3/9] START max_depth=2, max_leaf_nodes=50..............................\n",
      "[CV 4/5; 3/9] END max_depth=2, max_leaf_nodes=50;, score=0.016 total time=   1.8s\n",
      "[CV 5/5; 3/9] START max_depth=2, max_leaf_nodes=50..............................\n",
      "[CV 5/5; 3/9] END max_depth=2, max_leaf_nodes=50;, score=0.023 total time=   1.8s\n",
      "[CV 1/5; 4/9] START max_depth=4, max_leaf_nodes=5...............................\n",
      "[CV 1/5; 4/9] END max_depth=4, max_leaf_nodes=5;, score=0.027 total time=   3.3s\n",
      "[CV 2/5; 4/9] START max_depth=4, max_leaf_nodes=5...............................\n",
      "[CV 2/5; 4/9] END max_depth=4, max_leaf_nodes=5;, score=0.038 total time=   3.3s\n",
      "[CV 3/5; 4/9] START max_depth=4, max_leaf_nodes=5...............................\n",
      "[CV 3/5; 4/9] END max_depth=4, max_leaf_nodes=5;, score=0.036 total time=   3.4s\n",
      "[CV 4/5; 4/9] START max_depth=4, max_leaf_nodes=5...............................\n",
      "[CV 4/5; 4/9] END max_depth=4, max_leaf_nodes=5;, score=0.029 total time=   3.3s\n",
      "[CV 5/5; 4/9] START max_depth=4, max_leaf_nodes=5...............................\n",
      "[CV 5/5; 4/9] END max_depth=4, max_leaf_nodes=5;, score=0.038 total time=   3.3s\n",
      "[CV 1/5; 5/9] START max_depth=4, max_leaf_nodes=25..............................\n",
      "[CV 1/5; 5/9] END max_depth=4, max_leaf_nodes=25;, score=0.029 total time=   3.4s\n",
      "[CV 2/5; 5/9] START max_depth=4, max_leaf_nodes=25..............................\n",
      "[CV 2/5; 5/9] END max_depth=4, max_leaf_nodes=25;, score=0.038 total time=   3.3s\n",
      "[CV 3/5; 5/9] START max_depth=4, max_leaf_nodes=25..............................\n",
      "[CV 3/5; 5/9] END max_depth=4, max_leaf_nodes=25;, score=0.041 total time=   3.4s\n",
      "[CV 4/5; 5/9] START max_depth=4, max_leaf_nodes=25..............................\n",
      "[CV 4/5; 5/9] END max_depth=4, max_leaf_nodes=25;, score=0.031 total time=   3.4s\n",
      "[CV 5/5; 5/9] START max_depth=4, max_leaf_nodes=25..............................\n",
      "[CV 5/5; 5/9] END max_depth=4, max_leaf_nodes=25;, score=0.037 total time=   3.3s\n",
      "[CV 1/5; 6/9] START max_depth=4, max_leaf_nodes=50..............................\n",
      "[CV 1/5; 6/9] END max_depth=4, max_leaf_nodes=50;, score=0.029 total time=   3.3s\n",
      "[CV 2/5; 6/9] START max_depth=4, max_leaf_nodes=50..............................\n",
      "[CV 2/5; 6/9] END max_depth=4, max_leaf_nodes=50;, score=0.038 total time=   3.4s\n",
      "[CV 3/5; 6/9] START max_depth=4, max_leaf_nodes=50..............................\n",
      "[CV 3/5; 6/9] END max_depth=4, max_leaf_nodes=50;, score=0.041 total time=   3.4s\n",
      "[CV 4/5; 6/9] START max_depth=4, max_leaf_nodes=50..............................\n",
      "[CV 4/5; 6/9] END max_depth=4, max_leaf_nodes=50;, score=0.031 total time=   3.3s\n",
      "[CV 5/5; 6/9] START max_depth=4, max_leaf_nodes=50..............................\n",
      "[CV 5/5; 6/9] END max_depth=4, max_leaf_nodes=50;, score=0.037 total time=   3.3s\n",
      "[CV 1/5; 7/9] START max_depth=8, max_leaf_nodes=5...............................\n",
      "[CV 1/5; 7/9] END max_depth=8, max_leaf_nodes=5;, score=0.027 total time=   4.1s\n",
      "[CV 2/5; 7/9] START max_depth=8, max_leaf_nodes=5...............................\n",
      "[CV 2/5; 7/9] END max_depth=8, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 3/5; 7/9] START max_depth=8, max_leaf_nodes=5...............................\n",
      "[CV 3/5; 7/9] END max_depth=8, max_leaf_nodes=5;, score=0.036 total time=   4.1s\n",
      "[CV 4/5; 7/9] START max_depth=8, max_leaf_nodes=5...............................\n",
      "[CV 4/5; 7/9] END max_depth=8, max_leaf_nodes=5;, score=0.029 total time=   4.1s\n",
      "[CV 5/5; 7/9] START max_depth=8, max_leaf_nodes=5...............................\n",
      "[CV 5/5; 7/9] END max_depth=8, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 1/5; 8/9] START max_depth=8, max_leaf_nodes=25..............................\n",
      "[CV 1/5; 8/9] END max_depth=8, max_leaf_nodes=25;, score=0.030 total time=   6.3s\n",
      "[CV 2/5; 8/9] START max_depth=8, max_leaf_nodes=25..............................\n",
      "[CV 2/5; 8/9] END max_depth=8, max_leaf_nodes=25;, score=0.049 total time=   6.3s\n",
      "[CV 3/5; 8/9] START max_depth=8, max_leaf_nodes=25..............................\n",
      "[CV 3/5; 8/9] END max_depth=8, max_leaf_nodes=25;, score=0.051 total time=   6.4s\n",
      "[CV 4/5; 8/9] START max_depth=8, max_leaf_nodes=25..............................\n",
      "[CV 4/5; 8/9] END max_depth=8, max_leaf_nodes=25;, score=0.042 total time=   6.4s\n",
      "[CV 5/5; 8/9] START max_depth=8, max_leaf_nodes=25..............................\n",
      "[CV 5/5; 8/9] END max_depth=8, max_leaf_nodes=25;, score=0.045 total time=   6.3s\n",
      "[CV 1/5; 9/9] START max_depth=8, max_leaf_nodes=50..............................\n",
      "[CV 1/5; 9/9] END max_depth=8, max_leaf_nodes=50;, score=0.025 total time=   6.4s\n",
      "[CV 2/5; 9/9] START max_depth=8, max_leaf_nodes=50..............................\n",
      "[CV 2/5; 9/9] END max_depth=8, max_leaf_nodes=50;, score=0.048 total time=   6.3s\n",
      "[CV 3/5; 9/9] START max_depth=8, max_leaf_nodes=50..............................\n",
      "[CV 3/5; 9/9] END max_depth=8, max_leaf_nodes=50;, score=0.048 total time=   6.4s\n",
      "[CV 4/5; 9/9] START max_depth=8, max_leaf_nodes=50..............................\n",
      "[CV 4/5; 9/9] END max_depth=8, max_leaf_nodes=50;, score=0.040 total time=   6.4s\n",
      "[CV 5/5; 9/9] START max_depth=8, max_leaf_nodes=50..............................\n",
      "[CV 5/5; 9/9] END max_depth=8, max_leaf_nodes=50;, score=0.047 total time=   6.4s\n"
     ]
    }
   ],
   "source": [
    "# Using grid search for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# Setting parameters \n",
    "\n",
    "grid = {\"max_leaf_nodes\": [5, 25,50],\n",
    "        \"max_depth\":[2,4,8]}\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "\n",
    "model = GridSearchCV(estimator = dt, param_grid = grid, cv=5, verbose=10) # The \"cv\" option here is used to provide the desired number of folds K.\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf3636bf-f096-4c0d-bac8-549700d98465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.52763819, 2.04649157, 2.04649157, ..., 2.04649157, 2.04649157,\n",
       "       2.04649157])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4614e21-39bd-4995-848a-36ee3e7732fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was DecisionTreeRegressor(max_depth=8, max_leaf_nodes=25)\n",
      "MAE  0.60\n",
      "RMSE,  0.87\n",
      "R2 score,  0.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(f'The best model was {model.best_estimator_}')\n",
    "\n",
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8375d8c5-7964-4286-9b46-8d61d708378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START max_depth=1, max_leaf_nodes=5...............................\n",
      "[CV 1/5; 1/9] END max_depth=1, max_leaf_nodes=5;, score=0.016 total time=   1.0s\n",
      "[CV 2/5; 1/9] START max_depth=1, max_leaf_nodes=5...............................\n",
      "[CV 2/5; 1/9] END max_depth=1, max_leaf_nodes=5;, score=0.019 total time=   1.0s\n",
      "[CV 3/5; 1/9] START max_depth=1, max_leaf_nodes=5...............................\n",
      "[CV 3/5; 1/9] END max_depth=1, max_leaf_nodes=5;, score=0.020 total time=   1.0s\n",
      "[CV 4/5; 1/9] START max_depth=1, max_leaf_nodes=5...............................\n",
      "[CV 4/5; 1/9] END max_depth=1, max_leaf_nodes=5;, score=0.010 total time=   1.0s\n",
      "[CV 5/5; 1/9] START max_depth=1, max_leaf_nodes=5...............................\n",
      "[CV 5/5; 1/9] END max_depth=1, max_leaf_nodes=5;, score=0.020 total time=   1.0s\n",
      "[CV 1/5; 2/9] START max_depth=1, max_leaf_nodes=17..............................\n",
      "[CV 1/5; 2/9] END max_depth=1, max_leaf_nodes=17;, score=0.016 total time=   1.0s\n",
      "[CV 2/5; 2/9] START max_depth=1, max_leaf_nodes=17..............................\n",
      "[CV 2/5; 2/9] END max_depth=1, max_leaf_nodes=17;, score=0.019 total time=   1.0s\n",
      "[CV 3/5; 2/9] START max_depth=1, max_leaf_nodes=17..............................\n",
      "[CV 3/5; 2/9] END max_depth=1, max_leaf_nodes=17;, score=0.020 total time=   1.0s\n",
      "[CV 4/5; 2/9] START max_depth=1, max_leaf_nodes=17..............................\n",
      "[CV 4/5; 2/9] END max_depth=1, max_leaf_nodes=17;, score=0.010 total time=   1.0s\n",
      "[CV 5/5; 2/9] START max_depth=1, max_leaf_nodes=17..............................\n",
      "[CV 5/5; 2/9] END max_depth=1, max_leaf_nodes=17;, score=0.020 total time=   1.0s\n",
      "[CV 1/5; 3/9] START max_depth=1, max_leaf_nodes=30..............................\n",
      "[CV 1/5; 3/9] END max_depth=1, max_leaf_nodes=30;, score=0.016 total time=   1.1s\n",
      "[CV 2/5; 3/9] START max_depth=1, max_leaf_nodes=30..............................\n",
      "[CV 2/5; 3/9] END max_depth=1, max_leaf_nodes=30;, score=0.019 total time=   1.0s\n",
      "[CV 3/5; 3/9] START max_depth=1, max_leaf_nodes=30..............................\n",
      "[CV 3/5; 3/9] END max_depth=1, max_leaf_nodes=30;, score=0.020 total time=   1.0s\n",
      "[CV 4/5; 3/9] START max_depth=1, max_leaf_nodes=30..............................\n",
      "[CV 4/5; 3/9] END max_depth=1, max_leaf_nodes=30;, score=0.010 total time=   1.0s\n",
      "[CV 5/5; 3/9] START max_depth=1, max_leaf_nodes=30..............................\n",
      "[CV 5/5; 3/9] END max_depth=1, max_leaf_nodes=30;, score=0.020 total time=   1.0s\n",
      "[CV 1/5; 4/9] START max_depth=6, max_leaf_nodes=5...............................\n",
      "[CV 1/5; 4/9] END max_depth=6, max_leaf_nodes=5;, score=0.027 total time=   4.1s\n",
      "[CV 2/5; 4/9] START max_depth=6, max_leaf_nodes=5...............................\n",
      "[CV 2/5; 4/9] END max_depth=6, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 3/5; 4/9] START max_depth=6, max_leaf_nodes=5...............................\n",
      "[CV 3/5; 4/9] END max_depth=6, max_leaf_nodes=5;, score=0.036 total time=   4.2s\n",
      "[CV 4/5; 4/9] START max_depth=6, max_leaf_nodes=5...............................\n",
      "[CV 4/5; 4/9] END max_depth=6, max_leaf_nodes=5;, score=0.029 total time=   4.1s\n",
      "[CV 5/5; 4/9] START max_depth=6, max_leaf_nodes=5...............................\n",
      "[CV 5/5; 4/9] END max_depth=6, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 1/5; 5/9] START max_depth=6, max_leaf_nodes=17..............................\n",
      "[CV 1/5; 5/9] END max_depth=6, max_leaf_nodes=17;, score=0.031 total time=   4.9s\n",
      "[CV 2/5; 5/9] START max_depth=6, max_leaf_nodes=17..............................\n",
      "[CV 2/5; 5/9] END max_depth=6, max_leaf_nodes=17;, score=0.042 total time=   4.9s\n",
      "[CV 3/5; 5/9] START max_depth=6, max_leaf_nodes=17..............................\n",
      "[CV 3/5; 5/9] END max_depth=6, max_leaf_nodes=17;, score=0.050 total time=   4.9s\n",
      "[CV 4/5; 5/9] START max_depth=6, max_leaf_nodes=17..............................\n",
      "[CV 4/5; 5/9] END max_depth=6, max_leaf_nodes=17;, score=0.037 total time=   4.8s\n",
      "[CV 5/5; 5/9] START max_depth=6, max_leaf_nodes=17..............................\n",
      "[CV 5/5; 5/9] END max_depth=6, max_leaf_nodes=17;, score=0.040 total time=   4.9s\n",
      "[CV 1/5; 6/9] START max_depth=6, max_leaf_nodes=30..............................\n",
      "[CV 1/5; 6/9] END max_depth=6, max_leaf_nodes=30;, score=0.029 total time=   4.8s\n",
      "[CV 2/5; 6/9] START max_depth=6, max_leaf_nodes=30..............................\n",
      "[CV 2/5; 6/9] END max_depth=6, max_leaf_nodes=30;, score=0.042 total time=   4.8s\n",
      "[CV 3/5; 6/9] START max_depth=6, max_leaf_nodes=30..............................\n",
      "[CV 3/5; 6/9] END max_depth=6, max_leaf_nodes=30;, score=0.049 total time=   4.9s\n",
      "[CV 4/5; 6/9] START max_depth=6, max_leaf_nodes=30..............................\n",
      "[CV 4/5; 6/9] END max_depth=6, max_leaf_nodes=30;, score=0.035 total time=   4.8s\n",
      "[CV 5/5; 6/9] START max_depth=6, max_leaf_nodes=30..............................\n",
      "[CV 5/5; 6/9] END max_depth=6, max_leaf_nodes=30;, score=0.043 total time=   4.9s\n",
      "[CV 1/5; 7/9] START max_depth=11, max_leaf_nodes=5..............................\n",
      "[CV 1/5; 7/9] END max_depth=11, max_leaf_nodes=5;, score=0.027 total time=   4.1s\n",
      "[CV 2/5; 7/9] START max_depth=11, max_leaf_nodes=5..............................\n",
      "[CV 2/5; 7/9] END max_depth=11, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 3/5; 7/9] START max_depth=11, max_leaf_nodes=5..............................\n",
      "[CV 3/5; 7/9] END max_depth=11, max_leaf_nodes=5;, score=0.036 total time=   4.1s\n",
      "[CV 4/5; 7/9] START max_depth=11, max_leaf_nodes=5..............................\n",
      "[CV 4/5; 7/9] END max_depth=11, max_leaf_nodes=5;, score=0.029 total time=   4.1s\n",
      "[CV 5/5; 7/9] START max_depth=11, max_leaf_nodes=5..............................\n",
      "[CV 5/5; 7/9] END max_depth=11, max_leaf_nodes=5;, score=0.038 total time=   4.1s\n",
      "[CV 1/5; 8/9] START max_depth=11, max_leaf_nodes=17.............................\n",
      "[CV 1/5; 8/9] END max_depth=11, max_leaf_nodes=17;, score=0.045 total time=   8.6s\n",
      "[CV 2/5; 8/9] START max_depth=11, max_leaf_nodes=17.............................\n",
      "[CV 2/5; 8/9] END max_depth=11, max_leaf_nodes=17;, score=0.060 total time=   8.6s\n",
      "[CV 3/5; 8/9] START max_depth=11, max_leaf_nodes=17.............................\n",
      "[CV 3/5; 8/9] END max_depth=11, max_leaf_nodes=17;, score=0.055 total time=   8.6s\n",
      "[CV 4/5; 8/9] START max_depth=11, max_leaf_nodes=17.............................\n",
      "[CV 4/5; 8/9] END max_depth=11, max_leaf_nodes=17;, score=0.053 total time=   8.6s\n",
      "[CV 5/5; 8/9] START max_depth=11, max_leaf_nodes=17.............................\n",
      "[CV 5/5; 8/9] END max_depth=11, max_leaf_nodes=17;, score=0.050 total time=   8.6s\n",
      "[CV 1/5; 9/9] START max_depth=11, max_leaf_nodes=30.............................\n",
      "[CV 1/5; 9/9] END max_depth=11, max_leaf_nodes=30;, score=0.036 total time=   8.7s\n",
      "[CV 2/5; 9/9] START max_depth=11, max_leaf_nodes=30.............................\n",
      "[CV 2/5; 9/9] END max_depth=11, max_leaf_nodes=30;, score=0.060 total time=   8.8s\n",
      "[CV 3/5; 9/9] START max_depth=11, max_leaf_nodes=30.............................\n",
      "[CV 3/5; 9/9] END max_depth=11, max_leaf_nodes=30;, score=0.060 total time=   8.7s\n",
      "[CV 4/5; 9/9] START max_depth=11, max_leaf_nodes=30.............................\n",
      "[CV 4/5; 9/9] END max_depth=11, max_leaf_nodes=30;, score=0.051 total time=   8.7s\n",
      "[CV 5/5; 9/9] START max_depth=11, max_leaf_nodes=30.............................\n",
      "[CV 5/5; 9/9] END max_depth=11, max_leaf_nodes=30;, score=0.054 total time=   8.8s\n"
     ]
    }
   ],
   "source": [
    "# Using Random Search for decision tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting parameters \n",
    "\n",
    "grid = {\"max_leaf_nodes\": [int(x) for x in np.linspace(start = 5, stop = 30, num = 3)],\n",
    "        \"max_depth\":[int(x) for x in np.linspace(1, 11, num = 3)]}\n",
    "\n",
    "dt = DecisionTreeRegressor()\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "\n",
    "model = GridSearchCV(estimator = dt, param_grid = grid, cv=5, verbose=10) # The \"cv\" option here is used to provide the desired number of folds K.\n",
    "model.fit(X_train_split,y_train_split)\n",
    "\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3c9266a-8b50-4666-8f37-ae36f7777336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.71078431, 2.04088173, 2.04088173, ..., 3.16      , 2.04088173,\n",
       "       2.04088173])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24103443-e732-4506-b589-c4ac285e8bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was DecisionTreeRegressor(max_depth=11, max_leaf_nodes=17)\n",
      "MAE  0.60\n",
      "RMSE,  0.87\n",
      "R2 score,  0.07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "print(f'The best model was {model.best_estimator_}')\n",
    "\n",
    "# Evaluate the model and Report\n",
    "#func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,model)\n",
    "\n",
    "#print(classification_report(y_val_split, y_pred))\n",
    "#print(f'Validation Accuracy: {accuracy_score(y_val_split, y_pred): .2f}')\n",
    "print(f\"MAE {mean_absolute_error(y_pred, y_val_split): .2f}\") \n",
    "print(f\"RMSE, {root_mean_squared_error(y_pred, y_val_split): .2f}\")\n",
    "print(f\"R2 score, {model.score(X_train_split, y_train_split): .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d147dac2-82e0-4542-84a6-e4d9fa1474e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Hyperparameter Tuning for the best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc4f5267-5fdf-4ca4-b24b-acced1bdb8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Logistic Regression: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],  # Type of regularization\n",
    "    'solver': ['liblinear']  # liblinear is necessary for L1 regularization\n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "\n",
    "grid_search_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train_split,y_train_split)\n",
    "\n",
    "print(\"Best Parameters for Logistic Regression:\", grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "444bd680-462f-4de1-859b-f49d9b51367f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.18      0.23       280\n",
      "           1       0.44      0.32      0.37      1103\n",
      "           2       0.64      0.80      0.71      3069\n",
      "           3       0.48      0.41      0.44      1307\n",
      "           4       0.41      0.24      0.30       377\n",
      "\n",
      "    accuracy                           0.57      6136\n",
      "   macro avg       0.46      0.39      0.41      6136\n",
      "weighted avg       0.54      0.57      0.54      6136\n",
      "\n",
      "Validation Accuracy:  0.57\n",
      "MAE  0.51\n",
      "RMSE,  0.82\n",
      "R2 score,  0.73\n"
     ]
    }
   ],
   "source": [
    "# using the bes parameters and check th score again\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [10], \n",
    "    'penalty': ['l2'],  \n",
    "    'solver': ['liblinear']  \n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "grid_search_lr = GridSearchCV(log_reg, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train_split,y_train_split)\n",
    "y_pred = grid_search_lr.predict(X_val_split)\n",
    "func.print_evaluation(y_val_split , y_pred,X_train_split, y_train_split,grid_search_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "13eab960-a4e3-4419-96b1-7174a038bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b384faf6-2d9d-4656-8849-757b15a9753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermittently pleasing routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermittently pleasing routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>long wind predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>long wind predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>long winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>long winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId  \\\n",
       "0        156061        8545   \n",
       "1        156062        8545   \n",
       "2        156063        8545   \n",
       "3        156064        8545   \n",
       "4        156065        8545   \n",
       "...         ...         ...   \n",
       "66287    222348       11855   \n",
       "66288    222349       11855   \n",
       "66289    222350       11855   \n",
       "66290    222351       11855   \n",
       "66291    222352       11855   \n",
       "\n",
       "                                                  Phrase  \\\n",
       "0      An intermittently pleasing but mostly routine ...   \n",
       "1      An intermittently pleasing but mostly routine ...   \n",
       "2                                                     An   \n",
       "3      intermittently pleasing but mostly routine effort   \n",
       "4             intermittently pleasing but mostly routine   \n",
       "...                                                  ...   \n",
       "66287             A long-winded , predictable scenario .   \n",
       "66288               A long-winded , predictable scenario   \n",
       "66289                                    A long-winded ,   \n",
       "66290                                      A long-winded   \n",
       "66291                               predictable scenario   \n",
       "\n",
       "                                 cleaned_text  \n",
       "0      intermittently pleasing routine effort  \n",
       "1      intermittently pleasing routine effort  \n",
       "2                                              \n",
       "3      intermittently pleasing routine effort  \n",
       "4             intermittently pleasing routine  \n",
       "...                                       ...  \n",
       "66287          long wind predictable scenario  \n",
       "66288          long wind predictable scenario  \n",
       "66289                             long winded  \n",
       "66290                             long winded  \n",
       "66291                    predictable scenario  \n",
       "\n",
       "[66292 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b6d2d-3c6e-4fe4-b209-032e3963b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly']  # Different kernel types\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "grid_search_svm = GridSearchCV(svm, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_search_svm.fit(X_train_split,y_train_split)\n",
    "\n",
    "print(\"Best Parameters for SVM:\", grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a391aaa-1d6e-44dd-8d52-730e7cf49f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        156061\n",
       "1        156062\n",
       "2        156063\n",
       "3        156064\n",
       "4        156065\n",
       "          ...  \n",
       "66287    222348\n",
       "66288    222349\n",
       "66289    222350\n",
       "66290    222351\n",
       "66291    222352\n",
       "Name: PhraseId, Length: 66292, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.PhraseId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c13aa1c-7a27-41ac-8d2d-e57ff0a94383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  Sentiment\n",
       "0    156061          3\n",
       "1    156062          3\n",
       "2    156063          2\n",
       "3    156064          3\n",
       "4    156065          3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PhraseId': df_test.PhraseId,  # This should be the ID column from the test data\n",
    "    'Sentiment': y_pred  # Your prediction array\n",
    "})\n",
    "\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80678944-c194-4a62-9cfb-af3162d011ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../data/clean/submission', index=False)  # Save the file without the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707e3fc-bb64-4e95-83f3-d0794c469051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_env",
   "language": "python",
   "name": "proj_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
